{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZdaBgD1AtUU",
        "outputId": "c06026e9-015b-4124-beb9-bc4eaedd1ac8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!for i in {1..6}; do tar -xf \"/content/drive/MyDrive/KUBIG_melon/melon-dataset/arena_mel_${i}.tar\" -C \"/content\"; done"
      ],
      "metadata": {
        "id": "WD8SWMPotV0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songmeta_path = '/content/drive/MyDrive/KUBIG_melon/song_meta.json'\n",
        "with open(songmeta_path, 'r', encoding='utf-8') as f:\n",
        "    song_meta_json = json.load(f)\n",
        "song_meta = pd.DataFrame(song_meta_json)"
      ],
      "metadata": {
        "id": "mQtoB_qMAyQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "song_meta_1 = song_meta[(song_meta['song_gn_gnr_basket'].apply(len) == 1)]\n",
        "song_meta_1 = song_meta_1[~song_meta_1['song_gn_gnr_basket'].apply(lambda x: 'GN0500' in x)]"
      ],
      "metadata": {
        "id": "bHBd7L8fBA6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride = 1):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\n",
        "                nn.BatchNorm2d(planes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=(3,7), padding=(1,3)),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.layer1 = ResBlock(32, 64, stride=(2,2))\n",
        "        self.layer2 = ResBlock(64, 128, stride=(2,2))\n",
        "        self.layer3 = ResBlock(128, 256, stride=(2,2))\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.squeeze(-1).squeeze(-1)\n",
        "        return self.fc(x)\n",
        "\n",
        "def load_model(weight_path, num_classes):\n",
        "    model = ResNet(num_classes)\n",
        "    model.load_state_dict(torch.load(weight_path, map_location=DEVICE))\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "GENRE_MAP = {\n",
        "    'GN0100': \"발라드\",\n",
        "    'GN0200': \"댄스\",\n",
        "    'GN0300': \"랩/힙합\", #국내\n",
        "    'GN0400': \"R&B/Soul\", #국내\n",
        "    'GN0600': \"록/메탈\", #국내\n",
        "    'GN0700': \"성인가요\",\n",
        "    'GN0800': \"포크/블루스\", #국내\n",
        "    'GN0900': \"POP\",\n",
        "    'GN1000': \"록/메탈\", #해외\n",
        "    'GN1100': \"일렉트로니카\", #해외\n",
        "    'GN1200': \"랩/힙합\",\n",
        "    'GN1300': \"R&B/Soul\",\n",
        "    'GN1400': \"포크/블루스\",\n",
        "    'GN1500': \"OST\",\n",
        "    'GN1600': \"클래식\",\n",
        "    'GN1700': \"재즈\",\n",
        "    'GN1800': \"뉴에이지\",\n",
        "    'GN1900': \"J-POP\",\n",
        "    'GN2000': \"월드뮤직\",\n",
        "    'GN2100': \"CCM\",\n",
        "    'GN2200': \"어린이/태교\",\n",
        "    'GN2300': \"종교음악\",\n",
        "    'GN2400': \"국악\",\n",
        "    'GN2600': \"일렉트로니카(스타일)\",\n",
        "    'GN2700': \"EDM\",\n",
        "    'GN2800': \"뮤직테라피\",\n",
        "    'GN9000': \"UNKNOWN\"\n",
        "}"
      ],
      "metadata": {
        "id": "ZOEeIHQSvQGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "song_meta_1['genre'] = song_meta_1['song_gn_gnr_basket'].str[0].map(GENRE_MAP)\n",
        "song_meta_1['label'] = le.fit_transform(song_meta_1['genre'].str[0])\n",
        "song_meta_2 = song_meta_1[['id', 'label']]\n",
        "song_meta_100k = song_meta_2.iloc[:100000]\n",
        "train_df, test_df = train_test_split(song_meta_100k, test_size=0.2, stratify=song_meta_100k['label'], random_state=42)"
      ],
      "metadata": {
        "id": "tTQHsa2Pd0_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MelDataset(Dataset):\n",
        "  def __init__(self, df, mel_root, target_len = 1024):\n",
        "    self.df = df.reset_index(drop=True)\n",
        "    self.mel_root = mel_root\n",
        "    self.target_len = target_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    song_id = int(row['id'])\n",
        "    subdir = song_id // 1000\n",
        "    mel_path = os.path.join(self.mel_root, str(subdir), f'{song_id}.npy')\n",
        "    try:\n",
        "      mel = np.load(mel_path).astype(np.float32)\n",
        "    except ValueError:\n",
        "      print('error')\n",
        "      return self.__getitem__((idx+1) % len(self.df))\n",
        "    t = mel.shape[1]\n",
        "    if t > self.target_len:\n",
        "      start = np.random.randint(0, t-self.target_len)\n",
        "      mel = mel[:, start:(start+self.target_len)]\n",
        "    elif t < self.target_len:\n",
        "      mel = np.pad(mel, ((0, 0), (0, self.target_len - t)), mode='constant')\n",
        "    mel = (mel - mel.mean(axis=1, keepdims=True)) / (mel.std(axis=1, keepdims=True) + 1e-6)\n",
        "\n",
        "    mel = torch.tensor(mel).unsqueeze(0)\n",
        "    label = torch.tensor(row['label'], dtype=torch.long)\n",
        "    return mel, label"
      ],
      "metadata": {
        "id": "CgQYaun6eEGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = MelDataset(train_df, '/content/arena_mel/')\n",
        "test_ds = MelDataset(test_df, '/content/arena_mel/')\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "BI6odbgkelgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_planes, planes, stride = 1):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size = 1, stride = stride, bias = False),\n",
        "                nn.BatchNorm2d(planes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=(3, 11), padding=(1,3)),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.layer1 = ResBlock(32, 64, stride=(2,2))\n",
        "        self.layer2 = ResBlock(64, 128, stride=(2,2))\n",
        "        self.layer3 = ResBlock(128, 256, stride=(2,2))\n",
        "        self.layer4 = ResBlock(256, 256, stride=(2,2))\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.squeeze(-1).squeeze(-1)\n",
        "        return self.fc(x)"
      ],
      "metadata": {
        "id": "jfLsuUV6iP3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "num_classes = len(le.classes_)\n",
        "model = ResNet(num_classes=num_classes).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', patience=2, factor=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "JMTB6ec44GfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (mel, label) in enumerate(tqdm(train_loader)):\n",
        "        mel = mel.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(mel)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        pred = output.argmax(dim=1)\n",
        "        correct += (pred==label).sum().item()\n",
        "        total += label.size(0\n",
        "                            )\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(mel),\n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
        "                loss.item()))\n",
        "\n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    acc = correct / total\n",
        "    return avg_loss, acc\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for mel, label in test_loader:\n",
        "            mel = mel.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(mel)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += (pred==label).sum().item()\n",
        "\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    acc = 100. * correct / len(test_loader.dataset)\n",
        "    return avg_loss, acc"
      ],
      "metadata": {
        "id": "LUzvE5-U41n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 15"
      ],
      "metadata": {
        "id": "hkPHEEYY6wCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss = float('inf')\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    scheduler.step(test_loss)\n",
        "    if best_loss > test_loss:\n",
        "        best_loss = test_loss\n",
        "        torch.save(model.state_dict(), \"resnet_genre_best.pth\")\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv7kFgzR6yVJ",
        "outputId": "1dfe0737-4279-4cea-c35f-b3ca400b59fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1250 [00:00<14:19,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/80000 (0%)]\tTrain Loss: 1.528406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 201/1250 [02:20<12:18,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [12800/80000 (16%)]\tTrain Loss: 1.350456\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 401/1250 [04:40<09:47,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [25600/80000 (32%)]\tTrain Loss: 1.088271\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 601/1250 [07:00<07:26,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [38400/80000 (48%)]\tTrain Loss: 1.360782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 801/1250 [09:20<05:25,  1.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [51200/80000 (64%)]\tTrain Loss: 1.440672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 1001/1250 [11:39<02:50,  1.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [64000/80000 (80%)]\tTrain Loss: 1.359299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1201/1250 [13:58<00:34,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [76800/80000 (96%)]\tTrain Loss: 1.157754\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [14:32<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 1], \tTest Loss: 1.5314, \tTest Accuracy: 54.38 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1250 [00:00<13:41,  1.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [0/80000 (0%)]\tTrain Loss: 1.394554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 201/1250 [02:19<12:22,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [12800/80000 (16%)]\tTrain Loss: 1.160501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 401/1250 [04:38<09:46,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [25600/80000 (32%)]\tTrain Loss: 1.308773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 601/1250 [06:56<07:30,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [38400/80000 (48%)]\tTrain Loss: 1.110767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 801/1250 [09:15<05:11,  1.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [51200/80000 (64%)]\tTrain Loss: 1.187574\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 1001/1250 [11:34<02:47,  1.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [64000/80000 (80%)]\tTrain Loss: 1.059448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1201/1250 [13:53<00:34,  1.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 2 [76800/80000 (96%)]\tTrain Loss: 1.313403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1250/1250 [14:27<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[EPOCH: 2], \tTest Loss: 1.4352, \tTest Accuracy: 56.55 % \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/1250 [00:00<14:24,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 [0/80000 (0%)]\tTrain Loss: 1.149838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 201/1250 [02:20<12:32,  1.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 [12800/80000 (16%)]\tTrain Loss: 1.293726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 401/1250 [04:40<09:46,  1.45it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 3 [25600/80000 (32%)]\tTrain Loss: 1.399175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 402/1250 [04:41<09:45,  1.45it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"resnet_genre.pth\")"
      ],
      "metadata": {
        "id": "4sarkILdu4d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CIjyFPC0v7oC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}